{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jhayesn13/Test/blob/main/N_gram_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt', quiet=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nX5YWQ3692eM",
        "outputId": "2f9aca8d-32e3-413f-f0a7-61e4c4be82a1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-S0IjskckxJz",
        "outputId": "9a6a0b42-6115-491d-a69e-6ab27a3bdf14"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "# Corpus Only , with Option to set n as 1, 2, or 3\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Zj3mvq0b14i7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import random\n",
        "\n",
        "# Read the corpus from the text file\n",
        "def read_corpus(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        corpus = file.read()\n",
        "    return corpus\n",
        "\n",
        "# Tokenize the corpus into words\n",
        "def tokenize_corpus(corpus):\n",
        "    return nltk.word_tokenize(corpus)\n",
        "\n",
        "# Build an Ngram model\n",
        "def build_ngram_model(tokenized_corpus, n):\n",
        "    ngrams = {}\n",
        "    for i in range(len(tokenized_corpus)-n):\n",
        "        ngram = tuple(tokenized_corpus[i:i+n])\n",
        "        if ngram not in ngrams:\n",
        "            ngrams[ngram] = []\n",
        "        ngrams[ngram].append(tokenized_corpus[i+n])\n",
        "    return ngrams\n",
        "\n",
        "# Generate continuation for a prompt using the Ngram model\n",
        "def generate_continuation(prompt, ngrams, n, max_length=20):\n",
        "    prompt_words = nltk.word_tokenize(prompt)\n",
        "    if len(prompt_words) < n:\n",
        "        return \"Prompt length should be at least equal to the chosen N for the Ngram model.\"\n",
        "    else:\n",
        "        continuation = prompt\n",
        "        for _ in range(max_length):\n",
        "            last_n_words = tuple(prompt_words[-n:])\n",
        "            if last_n_words in ngrams:\n",
        "                next_word = random.choice(ngrams[last_n_words])\n",
        "                prompt_words.append(next_word)\n",
        "                continuation += \" \" + next_word\n",
        "            else:\n",
        "                break\n",
        "        # Check if continuation is empty\n",
        "        if continuation == prompt:\n",
        "            return \"I am sorry I don't have sufficient information to answer this one. Please Feed Me More Corpus !!!!\"\n",
        "        else:\n",
        "            return continuation\n",
        "\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    # Read the corpus\n",
        "    corpus_file = \"/content/website_text.txt\"\n",
        "    corpus = read_corpus(corpus_file)\n",
        "\n",
        "    # Tokenize the corpus\n",
        "    tokenized_corpus = tokenize_corpus(corpus)\n",
        "\n",
        "    # Choose the value of N for the Ngram model (e.g., 1 for unigrams, 2 for bigrams, etc.)\n",
        "    N = 3\n",
        "\n",
        "    # Build the Ngram model\n",
        "    ngram_model = build_ngram_model(tokenized_corpus, N)\n",
        "\n",
        "    # Prompts\n",
        "    starting_texts = [\n",
        "        \"In the fall semester, the business department offers courses such as\",\n",
        "        \"To apply for financial aid and scholarships, students must \",\n",
        "        \"to apply for a graduate degree students must\",\n",
        "        \"Graduate students have research opportunities in areas like\",\n",
        "        \"On-campus housing options provide amenities such as\",\n",
        "        \"The university's policies on academic integrity include guidelines like\",\n",
        "        \"Students can engage in extracurricular activities such as\",\n",
        "        \"Support for international students includes services like\",\n",
        "        \"Submitting a thesis or dissertation requires steps such as\",\n",
        "        \"The university's career center offers services like\"\n",
        "    ]\n",
        "\n",
        "    # Generate continuation for each prompt\n",
        "    for prompt in starting_texts:\n",
        "        print(\"Prompt:\", prompt)\n",
        "        continuation = generate_continuation(prompt, ngram_model, N)\n",
        "        print(\"Continuation:\", continuation)\n",
        "        print()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFW8lLnikTJk",
        "outputId": "8f9f7b02-b1e8-4a25-ff2f-1987168e54c8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: In the fall semester, the business department offers courses such as\n",
            "Continuation: I am sorry I don't have sufficient information to answer this one. Please Feed Me More Corpus !!!!\n",
            "\n",
            "Prompt: To apply for financial aid and scholarships, students must \n",
            "Continuation: To apply for financial aid and scholarships, students must  be between 16-17 years old , and proficient in English . ( Students should have the equivalent of a United\n",
            "\n",
            "Prompt: to apply for a graduate degree students must\n",
            "Continuation: I am sorry I don't have sufficient information to answer this one. Please Feed Me More Corpus !!!!\n",
            "\n",
            "Prompt: Graduate students have research opportunities in areas like\n",
            "Continuation: I am sorry I don't have sufficient information to answer this one. Please Feed Me More Corpus !!!!\n",
            "\n",
            "Prompt: On-campus housing options provide amenities such as\n",
            "Continuation: I am sorry I don't have sufficient information to answer this one. Please Feed Me More Corpus !!!!\n",
            "\n",
            "Prompt: The university's policies on academic integrity include guidelines like\n",
            "Continuation: I am sorry I don't have sufficient information to answer this one. Please Feed Me More Corpus !!!!\n",
            "\n",
            "Prompt: Students can engage in extracurricular activities such as\n",
            "Continuation: Students can engage in extracurricular activities such as role-plays to maximize English speaking skills . They will also attend classes taught by well-regarded professors in International Business |\n",
            "\n",
            "Prompt: Support for international students includes services like\n",
            "Continuation: I am sorry I don't have sufficient information to answer this one. Please Feed Me More Corpus !!!!\n",
            "\n",
            "Prompt: Submitting a thesis or dissertation requires steps such as\n",
            "Continuation: I am sorry I don't have sufficient information to answer this one. Please Feed Me More Corpus !!!!\n",
            "\n",
            "Prompt: The university's career center offers services like\n",
            "Continuation: I am sorry I don't have sufficient information to answer this one. Please Feed Me More Corpus !!!!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# Hybrid Approach, n=2/3\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "eXppV6-66GsV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-lhISZLF6Utk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import random\n",
        "\n",
        "# Read the corpus from the text file\n",
        "def read_corpus(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        corpus = file.read()\n",
        "    return corpus\n",
        "\n",
        "# Tokenize the corpus into words\n",
        "def tokenize_corpus(corpus):\n",
        "    return nltk.word_tokenize(corpus)\n",
        "\n",
        "# Build a mixed Ngram model (bigrams and trigrams)\n",
        "def build_mixed_ngram_model(tokenized_corpus):\n",
        "    ngrams = {}\n",
        "    # Incorporate both bigrams and trigrams\n",
        "    for n in range(2, 4):\n",
        "        for i in range(len(tokenized_corpus) - n):\n",
        "            ngram = tuple(tokenized_corpus[i:i + n])\n",
        "            next_word = tokenized_corpus[i + n]\n",
        "            if ngram not in ngrams:\n",
        "                ngrams[ngram] = []\n",
        "            ngrams[ngram].append(next_word)\n",
        "    return ngrams\n",
        "\n",
        "# Generate continuation using the mixed Ngram model\n",
        "def generate_continuation(prompt, ngrams, max_length=20):\n",
        "    prompt_words = nltk.word_tokenize(prompt)\n",
        "    continuation = prompt\n",
        "    for _ in range(max_length):\n",
        "        for n in range(3, 1, -1):  # Check trigrams first, then bigrams\n",
        "            last_n_words = tuple(prompt_words[-n:])\n",
        "            if last_n_words in ngrams:\n",
        "                next_word = random.choice(ngrams[last_n_words])\n",
        "                prompt_words.append(next_word)\n",
        "                continuation += \" \" + next_word\n",
        "                break\n",
        "        else:\n",
        "            break  # Break the outer loop if no n-grams match\n",
        "    return continuation if continuation != prompt else \"No continuation found. More diverse corpus might be needed.\"\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    # Read the corpus\n",
        "    corpus_file = \"/content/website_text.txt\"  # Adjust the path as necessary\n",
        "    corpus = read_corpus(corpus_file)\n",
        "\n",
        "    # Tokenize the corpus\n",
        "    tokenized_corpus = tokenize_corpus(corpus)\n",
        "\n",
        "    # Build the mixed Ngram model\n",
        "    ngram_model = build_mixed_ngram_model(tokenized_corpus)\n",
        "\n",
        "    # Sample prompts\n",
        "    starting_texts = [\n",
        "        \"In the fall semester, the business department offers courses such as\",\n",
        "        \"To apply for financial aid and scholarships, students must \",\n",
        "        \"to apply for a graduate degree students must\",\n",
        "        \"Graduate students have research opportunities in areas like\",\n",
        "        \"On-campus housing options provide amenities such as\",\n",
        "        \"The university's policies on academic integrity include guidelines like\",\n",
        "        \"Students can engage in extracurricular activities such as\",\n",
        "        \"Support for international students includes services like\",\n",
        "        \"Submitting a thesis or dissertation requires steps such as\",\n",
        "        \"The university's career center offers services like\"\n",
        "    ]\n",
        "    # Generate continuation for each prompt\n",
        "    for prompt in starting_texts:\n",
        "        print(\"Prompt:\", prompt)\n",
        "        continuation = generate_continuation(prompt, ngram_model)\n",
        "        print(\"Continuation:\", continuation)\n",
        "        print()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "sp_cRWm0v3__",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2729e0d8-eff2-4c5d-b8b0-9c12a1fc98e6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: In the fall semester, the business department offers courses such as\n",
            "Continuation: In the fall semester, the business department offers courses such as Regulations S-K , S-X , S-T , and S-B along with exemptions provided under Regulations A and D. Financial reporting\n",
            "\n",
            "Prompt: To apply for financial aid and scholarships, students must \n",
            "Continuation: To apply for financial aid and scholarships, students must  be in NYC . Career Outcomes The Master of Business Administration , please contact : Office of Graduate Admission The\n",
            "\n",
            "Prompt: to apply for a graduate degree students must\n",
            "Continuation: to apply for a graduate degree students must have , as a method of forecasting future financial and operating results , and as a means of diagnosing managerial\n",
            "\n",
            "Prompt: Graduate students have research opportunities in areas like\n",
            "Continuation: No continuation found. More diverse corpus might be needed.\n",
            "\n",
            "Prompt: On-campus housing options provide amenities such as\n",
            "Continuation: On-campus housing options provide amenities such as dances , sports activities and movies . It ’ s up to you what you do with it. ” Wendell\n",
            "\n",
            "Prompt: The university's policies on academic integrity include guidelines like\n",
            "Continuation: No continuation found. More diverse corpus might be needed.\n",
            "\n",
            "Prompt: Students can engage in extracurricular activities such as\n",
            "Continuation: Students can engage in extracurricular activities such as role-plays to maximize English speaking skills . They will also attend classes taught by well-regarded professors in International Business |\n",
            "\n",
            "Prompt: Support for international students includes services like\n",
            "Continuation: No continuation found. More diverse corpus might be needed.\n",
            "\n",
            "Prompt: Submitting a thesis or dissertation requires steps such as\n",
            "Continuation: Submitting a thesis or dissertation requires steps such as How to Write the College Application Essay , Tips for Summary Writing and The Art of Small Talk Apply Online\n",
            "\n",
            "Prompt: The university's career center offers services like\n",
            "Continuation: No continuation found. More diverse corpus might be needed.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# Higher Order with N=7 as max n-gram3\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "7X46nrpj6cKK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the corpus from the text file\n",
        "def read_corpus(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        corpus = file.read()\n",
        "    return corpus\n",
        "\n",
        "# Tokenize the corpus into words\n",
        "def tokenize_corpus(corpus):\n",
        "    return nltk.word_tokenize(corpus)\n",
        "\n",
        "# Build a flexible Ngram model supporting multiple orders\n",
        "def build_flexible_ngram_model(tokenized_corpus, max_n=5):\n",
        "    ngrams = {}\n",
        "    # Create N-grams for each order from 2 up to max_n\n",
        "    for n in range(2, max_n + 1):\n",
        "        for i in range(len(tokenized_corpus) - n):\n",
        "            ngram = tuple(tokenized_corpus[i:i + n])\n",
        "            next_word = tokenized_corpus[i + n]\n",
        "            if ngram not in ngrams:\n",
        "                ngrams[ngram] = []\n",
        "            ngrams[ngram].append(next_word)\n",
        "    return ngrams\n",
        "\n",
        "# Generate continuation using the flexible Ngram model\n",
        "def generate_continuation(prompt, ngrams, max_n, max_length=50):\n",
        "    prompt_words = nltk.word_tokenize(prompt)\n",
        "    continuation = prompt\n",
        "    for _ in range(max_length):\n",
        "        found = False\n",
        "        # Try from the highest order down to 2-grams\n",
        "        for n in range(max_n, 1, -1):\n",
        "            if len(prompt_words) >= n:\n",
        "                last_n_words = tuple(prompt_words[-n:])\n",
        "                if last_n_words in ngrams:\n",
        "                    next_word = random.choice(ngrams[last_n_words])\n",
        "                    prompt_words.append(next_word)\n",
        "                    continuation += \" \" + next_word\n",
        "                    found = True\n",
        "                    break\n",
        "        if not found:  # Break if no suitable N-gram was found\n",
        "            break\n",
        "    return continuation if continuation != prompt else \"No continuation found. More diverse corpus might be needed.\"\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    # Read the corpus\n",
        "    corpus_file = \"/content/website_text.txt\"  # Adjust the path as necessary\n",
        "    corpus = read_corpus(corpus_file)\n",
        "\n",
        "    # Tokenize the corpus\n",
        "    tokenized_corpus = tokenize_corpus(corpus)\n",
        "\n",
        "    # Build the flexible Ngram model\n",
        "    max_n = 7  # Can adjust based on desired complexity and corpus size\n",
        "    ngram_model = build_flexible_ngram_model(tokenized_corpus, max_n)\n",
        "\n",
        "    # Sample prompts\n",
        "    starting_texts = [\n",
        "        \"In the fall semester, the business department offers courses such as\",\n",
        "        \"To apply for financial aid and scholarships, students must \",\n",
        "        \"to apply for a graduate degree students must\",\n",
        "        \"Graduate students have research opportunities in areas like\",\n",
        "        \"On-campus housing options provide amenities such as\",\n",
        "        \"The university's policies on academic integrity include guidelines like\",\n",
        "        \"Students can engage in extracurricular activities such as\",\n",
        "        \"Support for international students includes services like\",\n",
        "        \"Submitting a thesis or dissertation requires steps such as\",\n",
        "        \"The university's career center offers services like\"\n",
        "    ]\n",
        "\n",
        "    # Generate continuation for each prompt\n",
        "    for prompt in starting_texts:\n",
        "        print(\"Prompt:\", prompt)\n",
        "        continuation = generate_continuation(prompt, ngram_model, max_n)\n",
        "        print(\"Continuation:\", continuation)\n",
        "        print()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "G4AyIfoExAbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# Pickling\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "XIS6DwHDJcE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "# Read the corpus from the text file\n",
        "def read_corpus(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        corpus = file.read()\n",
        "    return corpus\n",
        "\n",
        "# Tokenize the corpus into words\n",
        "def tokenize_corpus(corpus):\n",
        "    return nltk.word_tokenize(corpus)\n",
        "\n",
        "# Build a flexible Ngram model supporting multiple orders\n",
        "def build_flexible_ngram_model(tokenized_corpus, max_n=5):\n",
        "    ngrams = {}\n",
        "    for n in range(2, max_n + 1):\n",
        "        for i in range(len(tokenized_corpus) - n):\n",
        "            ngram = tuple(tokenized_corpus[i:i + n])\n",
        "            next_word = tokenized_corpus[i + n]\n",
        "            if ngram not in ngrams:\n",
        "                ngrams[ngram] = []\n",
        "            ngrams[ngram].append(next_word)\n",
        "    return ngrams\n",
        "\n",
        "# Generate continuation using the flexible Ngram model\n",
        "def generate_continuation(prompt, ngrams, max_n, max_length=50):\n",
        "    prompt_words = nltk.word_tokenize(prompt)\n",
        "    continuation = prompt\n",
        "    for _ in range(max_length):\n",
        "        found = False\n",
        "        for n in range(max_n, 1, -1):\n",
        "            if len(prompt_words) >= n:\n",
        "                last_n_words = tuple(prompt_words[-n:])\n",
        "                if last_n_words in ngrams:\n",
        "                    next_word = random.choice(ngrams[last_n_words])\n",
        "                    prompt_words.append(next_word)\n",
        "                    continuation += \" \" + next_word\n",
        "                    found = True\n",
        "                    break\n",
        "        if not found:\n",
        "            break\n",
        "    return continuation if continuation != prompt else \"No continuation found. More diverse corpus might be needed.\"\n",
        "\n",
        "# Function to save the model to a pickle file\n",
        "def save_model_to_pickle(model, file_name='ngram_model.pkl'):\n",
        "    with open(file_name, 'wb') as f:\n",
        "        pickle.dump(model, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    # Read the corpus\n",
        "    corpus_file = \"/content/website_text.txt\"  # Adjust the path as necessary\n",
        "    corpus = read_corpus(corpus_file)\n",
        "\n",
        "    # Tokenize the corpus\n",
        "    tokenized_corpus = tokenize_corpus(corpus)\n",
        "\n",
        "    # Build the flexible Ngram model\n",
        "    max_n = 7  # Can adjust based on desired complexity and corpus size\n",
        "    ngram_model = build_flexible_ngram_model(tokenized_corpus, max_n)\n",
        "\n",
        "    # Save the model to a pickle file\n",
        "    save_model_to_pickle(ngram_model, '/content/ngram_model.pkl')\n",
        "    print(\"N-Gram model has been built and saved as 'ngram_model.pkl'.\")\n",
        "\n",
        "    # Sample prompts\n",
        "    starting_texts = [\n",
        "        \"In the fall semester, the business department offers courses such as\",\n",
        "        \"To apply for financial aid and scholarships, students must \",\n",
        "        \"To apply for a graduate degree students must\",\n",
        "        \"Graduate students have research opportunities in areas like\",\n",
        "        \"On-campus housing options provide amenities such as\",\n",
        "        \"The university's policies on academic integrity include guidelines like\",\n",
        "        \"Students can engage in extracurricular activities such as\",\n",
        "        \"Support for international students includes services like\",\n",
        "        \"Submitting a thesis or dissertation requires steps such as\",\n",
        "        \"The university's career center offers services like\"\n",
        "    ]\n",
        "\n",
        "    # Generate continuation for each prompt\n",
        "    for prompt in starting_texts:\n",
        "        print(\"Prompt:\", prompt)\n",
        "        continuation = generate_continuation(prompt, ngram_model, max_n)\n",
        "        print(\"Continuation:\", continuation)\n",
        "        print()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMJLPefKCLDi",
        "outputId": "4cfc29c3-d70e-446c-ef77-186650680b57"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N-Gram model has been built and saved as 'ngram_model.pkl'.\n",
            "Prompt: In the fall semester, the business department offers courses such as\n",
            "Continuation: In the fall semester, the business department offers courses such as literature , philosophy , and history . Studying the humanities allows you to explore a wide range of disciplines as you strengthen your research , writing , and critical thinking skills . Why St. John's Whether you pursue one of these social sciences at St. John ’ s—or a combination\n",
            "\n",
            "Prompt: To apply for financial aid and scholarships, students must \n",
            "Continuation: To apply for financial aid and scholarships, students must  be between 16-17 years old , and proficient in English . ( Students should have the equivalent of a B2 level on the CEFR . ) If English is not your native language , please review the chart found here to determine whether your English proficiency meets this requirement .\n",
            "\n",
            "Prompt: To apply for a graduate degree students must\n",
            "Continuation: To apply for a graduate degree students must attend this on-site workshop . What is the cost of tuition for the program ? Program tuition for the current academic year is $ 1,280 per credit hour . Learn more about tuition and fees by visiting our Tuition page . Is the program accredited ? Yes . St. John\n",
            "\n",
            "Prompt: Graduate students have research opportunities in areas like\n",
            "Continuation: No continuation found. More diverse corpus might be needed.\n",
            "\n",
            "Prompt: On-campus housing options provide amenities such as\n",
            "Continuation: On-campus housing options provide amenities such as external financial reporting ; planning , budgeting and forecasting ; performance management ; cost management ; internal controls ; financial statement analysis ; corporate treasury ; decision analysis ; investment decisions ; risk management ; and professional ethics . International and U.S. case studies will be assigned to demonstrate the\n",
            "\n",
            "Prompt: The university's policies on academic integrity include guidelines like\n",
            "Continuation: No continuation found. More diverse corpus might be needed.\n",
            "\n",
            "Prompt: Students can engage in extracurricular activities such as\n",
            "Continuation: Students can engage in extracurricular activities such as role-plays to maximize English speaking skills . They will also attend classes taught by well-regarded professors in International Business concepts such as finance , marketing and design , technology and intellectual property rights . To apply the language and concepts learned in these workshops , and learn team-building skills ,\n",
            "\n",
            "Prompt: Support for international students includes services like\n",
            "Continuation: No continuation found. More diverse corpus might be needed.\n",
            "\n",
            "Prompt: Submitting a thesis or dissertation requires steps such as\n",
            "Continuation: Submitting a thesis or dissertation requires steps such as sales , use , excise , and a variety of other transaction taxes ; transfer taxes such as estate , gift , and inheritance taxes ; value-added taxes ; and property taxes . TAX 654 Transfer Pricing ( 3 credit hours ) Prerequisite : ACC 650/equivalent . This course introduces\n",
            "\n",
            "Prompt: The university's career center offers services like\n",
            "Continuation: No continuation found. More diverse corpus might be needed.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# GPT Base\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "h1KKQJ8UDtxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gpt-2-simple\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTJksVjJHpXB",
        "outputId": "81f54559-ba8a-4cdd-b519-5074bc37aee1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gpt-2-simple\n",
            "  Using cached gpt_2_simple-0.8.1.tar.gz (26 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tensorflow>=2.5.1 in /usr/local/lib/python3.10/dist-packages (from gpt-2-simple) (2.15.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from gpt-2-simple) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from gpt-2-simple) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gpt-2-simple) (4.66.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from gpt-2-simple) (1.25.2)\n",
            "Collecting toposort (from gpt-2-simple)\n",
            "  Downloading toposort-1.10-py3-none-any.whl (8.5 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.62.2)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (2.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->gpt-2-simple) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->gpt-2-simple) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->gpt-2-simple) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->gpt-2-simple) (2024.2.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.5.1->gpt-2-simple) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.5.1->gpt-2-simple) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.5.1->gpt-2-simple) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.5.1->gpt-2-simple) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.5.1->gpt-2-simple) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.5.1->gpt-2-simple) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.5.1->gpt-2-simple) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.5.1->gpt-2-simple) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.5.1->gpt-2-simple) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.5.1->gpt-2-simple) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow>=2.5.1->gpt-2-simple) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.5.1->gpt-2-simple) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.5.1->gpt-2-simple) (3.2.2)\n",
            "Building wheels for collected packages: gpt-2-simple\n",
            "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpt-2-simple: filename=gpt_2_simple-0.8.1-py3-none-any.whl size=24557 sha256=924c077176f5ab45bf702a3cfe8dbd354b6b4a3faa922b770c061a1098924f23\n",
            "  Stored in directory: /root/.cache/pip/wheels/df/6a/fe/10d3223f78d1ac3e4c83bb4c5e2d28dfb1789c2fb4cc7ea8d0\n",
            "Successfully built gpt-2-simple\n",
            "Installing collected packages: toposort, gpt-2-simple\n",
            "Successfully installed gpt-2-simple-0.8.1 toposort-1.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gpt_2_simple as gpt2\n",
        "\n",
        "model_name = \"124M\"  # Choose model size\n",
        "gpt2.download_gpt2(model_name=model_name)  # Downloads the model files to /models/124M/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SdrSau6vll_",
        "outputId": "eae40c1b-4eff-4699-f9ff-91517fa2abeb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 2.38Git/s]                                                     \n",
            "Fetching encoder.json: 1.05Mit [00:00, 2.53Mit/s]\n",
            "Fetching hparams.json: 1.05Mit [00:00, 3.45Git/s]                                                   \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:14, 33.8Mit/s]                                  \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 1.14Git/s]                                               \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 3.54Mit/s]\n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 4.20Mit/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gpt_2_simple as gpt2\n",
        "\n",
        "# Function to generate continuation using GPT-2 model\n",
        "def generate_gpt2_continuation(prompt, length=50):\n",
        "    # Start a new TensorFlow session\n",
        "    sess = gpt2.start_tf_sess()\n",
        "\n",
        "    try:\n",
        "        # Load the pre-trained GPT-2 model\n",
        "        gpt2.load_gpt2(sess, model_name=\"124M\")\n",
        "\n",
        "        # Generate continuation\n",
        "        continuation = gpt2.generate(sess,\n",
        "                                     model_name=\"124M\",\n",
        "                                     prefix=prompt,\n",
        "                                     length=length,\n",
        "                                     return_as_list=True)[0]\n",
        "    finally:\n",
        "        # Close the TensorFlow session to avoid the warning\n",
        "        gpt2.reset_session(sess)\n",
        "\n",
        "    return continuation\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    # Prompts\n",
        "    starting_texts = [\n",
        "        \"In the fall semester, the business department offers courses such as\",\n",
        "        \"To apply for financial aid and scholarships, students must \",\n",
        "        \"to apply for a graduate degree students must\",\n",
        "        \"Graduate students have research opportunities in areas like\",\n",
        "        \"On-campus housing options provide amenities such as\",\n",
        "        \"The university's policies on academic integrity include guidelines like\",\n",
        "        \"Students can engage in extracurricular activities such as\",\n",
        "        \"Support for international students includes services like\",\n",
        "        \"Submitting a thesis or dissertation requires steps such as\",\n",
        "        \"The university's career center offers services like\"\n",
        "    ]\n",
        "\n",
        "    # Generate continuation for each prompt using GPT-2\n",
        "    for prompt in starting_texts:\n",
        "        print(\"Prompt:\", prompt)\n",
        "        continuation = generate_gpt2_continuation(prompt)\n",
        "        print(\"Continuation:\", continuation)\n",
        "        print()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "76Fcyc605zYz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89f0bf90-c727-466d-97a5-90b4c20c6bff"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: In the fall semester, the business department offers courses such as\n",
            "Loading pretrained model models/124M/model.ckpt\n",
            "Continuation: In the fall semester, the business department offers courses such as SMART Accounting and General Accounting. A single course may be required to complete the course. The class is offered as a part of the regular business class. Please see the discussion and class schedule for more information.\n",
            "\n",
            "Students can also complete the course\n",
            "\n",
            "Prompt: To apply for financial aid and scholarships, students must \n",
            "Loading pretrained model models/124M/model.ckpt\n",
            "Continuation: To apply for financial aid and scholarships, students must  have been accepted by the University as of the age of 21. We recommend Apply For Financial Aid and Scholarships if you are a student who is applying for aid and scholarships, or if you are seeking financial assistance to help you fulfill your dream of\n",
            "\n",
            "Prompt: to apply for a graduate degree students must\n",
            "Loading pretrained model models/124M/model.ckpt\n",
            "Continuation: to apply for a graduate degree students must make a business course.\n",
            "\n",
            "If you are working in an industry or a profession that requires you to take a graduate degree, you should apply for a graduate degree from a business school. If you are working in an industry or a profession that requires\n",
            "\n",
            "Prompt: Graduate students have research opportunities in areas like\n",
            "Loading pretrained model models/124M/model.ckpt\n",
            "Continuation: Graduate students have research opportunities in areas like ecology and paleontology, and graduate students will also be able to explore the connection between the Italian plant life and the fossil record.\n",
            "\n",
            "Each year, the National Institute of Economic Sciences will host a state-of-the-art 10-\n",
            "\n",
            "Prompt: On-campus housing options provide amenities such as\n",
            "Loading pretrained model models/124M/model.ckpt\n",
            "Continuation: On-campus housing options provide amenities such as free Wi-Fi, online courses, and communication with friends and family.\n",
            "\n",
            "The University is cognizant of the potential negative impact of a shortage of affordable housing. It strongly encourages students to pursue affordable housing options, which for some students is\n",
            "\n",
            "Prompt: The university's policies on academic integrity include guidelines like\n",
            "Loading pretrained model models/124M/model.ckpt\n",
            "Continuation: The university's policies on academic integrity include guidelines like that of the American Association of University Professors and the Insights and Evaluation Council.\n",
            "\n",
            "\"The right of students to have their academic integrity evaluated is an important pillar of our university system and it is part of what we fund our academic mission,\"\n",
            "\n",
            "Prompt: Students can engage in extracurricular activities such as\n",
            "Loading pretrained model models/124M/model.ckpt\n",
            "Continuation: Students can engage in extracurricular activities such as sports, pre-workout, and creative writing.\n",
            "\n",
            "Each year, Friday – Saturday elementary schools in the Atlanta area provide free public school lunches.\n",
            "\n",
            "\"It's just too expensive and they have to make sure they keep it within\n",
            "\n",
            "Prompt: Support for international students includes services like\n",
            "Loading pretrained model models/124M/model.ckpt\n",
            "Continuation: Support for international students includes services like the U.S. Refugee Admissions Program, which assists U.S. students with information regarding their opportunities to pursue a degree in the United States and international students are highly encouraged to apply for DACA and to apply for a visa and community-based\n",
            "\n",
            "Prompt: Submitting a thesis or dissertation requires steps such as\n",
            "Loading pretrained model models/124M/model.ckpt\n",
            "Continuation: Submitting a thesis or dissertation requires steps such as:\n",
            "\n",
            "Completed work in a lab setting;\n",
            "\n",
            "A financial commitment from the applicant for a post-doc position.\n",
            "\n",
            "You may also submit your thesis or dissertation through the University of California Press, or through a Blue Book.\n",
            "\n",
            "\n",
            "\n",
            "Prompt: The university's career center offers services like\n",
            "Loading pretrained model models/124M/model.ckpt\n",
            "Continuation: The university's career center offers services like academic advising, research and reflection, public relations, political science, and research.\n",
            "\n",
            "The center can help students with financial worries and other challenges. It also offers well-rounded counseling, psychology, and other community education.\n",
            "\n",
            "Students are encouraged\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# GPT Base With Web Crawler Corpus Integrated\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "jhIoFLpaJIZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gpt_2_simple as gpt2\n",
        "\n",
        "# Function to fine-tune GPT-2 model on a given corpus\n",
        "def fine_tune_gpt2(corpus_path):\n",
        "    # Start a new TensorFlow session\n",
        "    sess = gpt2.start_tf_sess()\n",
        "\n",
        "    try:\n",
        "        # Fine-tune the pre-trained GPT-2 model on the given corpus\n",
        "        gpt2.finetune(sess,\n",
        "                      dataset=corpus_path,\n",
        "                      model_name='124M',\n",
        "                      steps=5)  # You can adjust the number of training steps as needed\n",
        "    finally:\n",
        "        # Close the TensorFlow session\n",
        "        gpt2.reset_session(sess)\n",
        "\n",
        "# Function to generate continuation using fine-tuned GPT-2 model\n",
        "def generate_gpt2_continuation(prompt, length=50):\n",
        "    # Start a new TensorFlow session\n",
        "    sess = gpt2.start_tf_sess()\n",
        "\n",
        "    try:\n",
        "        # Load the fine-tuned GPT-2 model\n",
        "        gpt2.load_gpt2(sess, model_name=\"124M\")\n",
        "\n",
        "        # Generate continuation\n",
        "        continuation = gpt2.generate(sess,\n",
        "                                     model_name=\"124M\",\n",
        "                                     prefix=prompt,\n",
        "                                     length=length,\n",
        "                                     return_as_list=True)[0]\n",
        "    finally:\n",
        "        # Close the TensorFlow session to avoid the warning\n",
        "        gpt2.reset_session(sess)\n",
        "\n",
        "    return continuation\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    # Fine-tune GPT-2 on your corpus\n",
        "    corpus_path = \"/content/website_text.txt\"\n",
        "    fine_tune_gpt2(corpus_path)\n",
        "\n",
        "    # Prompts\n",
        "    starting_texts = [\n",
        "        \"In the fall semester, the business department offers courses such as\",\n",
        "        \"To apply for financial aid and scholarships, students must \",\n",
        "        \"to apply for a graduate degree students must\",\n",
        "        \"Graduate students have research opportunities in areas like\",\n",
        "        \"On-campus housing options provide amenities such as\",\n",
        "        \"The university's policies on academic integrity include guidelines like\",\n",
        "        \"Students can engage in extracurricular activities such as\",\n",
        "        \"Support for international students includes services like\",\n",
        "        \"Submitting a thesis or dissertation requires steps such as\",\n",
        "        \"The university's career center offers services like\"\n",
        "    ]\n",
        "\n",
        "    # Generate continuation for each prompt using fine-tuned GPT-2\n",
        "    for prompt in starting_texts:\n",
        "        print(\"Prompt:\", prompt)\n",
        "        continuation = generate_gpt2_continuation(prompt)\n",
        "        print(\"Continuation:\", continuation)\n",
        "        print()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lj8f5aBnJF2Q",
        "outputId": "40b16058-6eb9-46d3-94f7-f02b9dcba9be"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint models/124M/model.ckpt\n",
            "Loading dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [01:37<00:00, 97.74s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset has 17668215 tokens\n",
            "Training...\n",
            "[1 | 134.20] loss=7.60 avg=7.60\n",
            "[2 | 264.28] loss=8.96 avg=8.29\n",
            "[3 | 394.72] loss=6.85 avg=7.80\n",
            "[4 | 523.01] loss=6.70 avg=7.52\n",
            "[5 | 655.56] loss=7.07 avg=7.43\n",
            "Saving checkpoint/run1/model-5\n",
            "Prompt: In the fall semester, the business department offers courses such as\n",
            "Loading pretrained model models/124M/model.ckpt\n",
            "Continuation: In the fall semester, the business department offers courses such as the Business and Finance Department, a different course and a third-year course in the economics department, as well as a two-course course in career development.\n",
            "\n",
            "The university's main campus is on the western edge of downtown Vancouver. It is\n",
            "\n",
            "Prompt: To apply for financial aid and scholarships, students must \n",
            "Loading pretrained model models/124M/model.ckpt\n",
            "Continuation: To apply for financial aid and scholarships, students must  be able to submit a letter of recommendation. The Scholars Program is not accepted in Michigan. The Scholars Program is a federally funded program that provides financial aid to students. The Scholars Program is available to students in the following states and is not accepted in\n",
            "\n",
            "Prompt: to apply for a graduate degree students must\n",
            "Loading pretrained model models/124M/model.ckpt\n",
            "Continuation: to apply for a graduate degree students must apply for the Graduate Certificate in Linguistics, Literature, or History (GCHL) program at the University of Michigan.\n",
            "\n",
            "Students must take a section D-2 (HEC) course that satisfies all requirements. The HEC course\n",
            "\n",
            "Prompt: Graduate students have research opportunities in areas like\n",
            "Loading pretrained model models/124M/model.ckpt\n",
            "Continuation: Graduate students have research opportunities in areas like Kinesiology, Medicine and Philosophy.\n",
            "\n",
            "Lecture Notes\n",
            "\n",
            "In addition to the faculty of the University of Illinois at Chicago, the Center for Advanced Study provides specialized training and training for researchers in the areas of Cognitive Science, Psychology,\n",
            "\n",
            "Prompt: On-campus housing options provide amenities such as\n",
            "Loading pretrained model models/124M/model.ckpt\n",
            "Continuation: On-campus housing options provide amenities such as dining, a living room, and a library. Students can choose either a private campus or a public campus for their own use.\n",
            "\n",
            "Students who live on the campus will be able to adjust the cost of their living to accommodate the new shared spaces\n",
            "\n",
            "Prompt: The university's policies on academic integrity include guidelines like\n",
            "Loading pretrained model models/124M/model.ckpt\n",
            "Continuation: The university's policies on academic integrity include guidelines like its \"Code of Ethics\" that show \"no bias\" to academics.\n",
            "\n",
            "The university's Board of Governors, which includes faculty, students and staff, has said it is committed to ensuring the safety of its students and to ensuring that \"safe\n",
            "\n",
            "Prompt: Students can engage in extracurricular activities such as\n",
            "Loading pretrained model models/124M/model.ckpt\n",
            "Continuation: Students can engage in extracurricular activities such as music, dance, or video games.\n",
            "\n",
            "______________________________\n",
            "\n",
            "This is a budget-limited program. The cost of the program is $25 per person and a $15 fee per family member.\n",
            "\n",
            "Planned classes are:\n",
            "\n",
            "\n",
            "\n",
            "Prompt: Support for international students includes services like\n",
            "Loading pretrained model models/124M/model.ckpt\n",
            "Continuation: Support for international students includes services like free office space, the opportunity to look into the future and the opportunity to keep your job, and other opportunities.\n",
            "\n",
            "If you are a student, you must have a student visa, to get a job in Australia.\n",
            "\n",
            "If you have\n",
            "\n",
            "Prompt: Submitting a thesis or dissertation requires steps such as\n",
            "Loading pretrained model models/124M/model.ckpt\n",
            "Continuation: Submitting a thesis or dissertation requires steps such as a peer-reviewed journal entry, peer-reviewed peer-reviewed article, and peer-reviewed academic review. The National Academies of Sciences and Engineering explain how to apply this standard.\n",
            "\n",
            "Prior to submitting a thesis or dissertation, the applicant must\n",
            "\n",
            "Prompt: The university's career center offers services like\n",
            "Loading pretrained model models/124M/model.ckpt\n",
            "Continuation: The university's career center offers services like medical, academic, and clinical services, as well as vocational and career development.\n",
            "\n",
            "The university's focus is to include a vibrant student population and an atmosphere where any student can learn, learn, and enjoy their own culture.\n",
            "\n",
            "\"With\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gehiPWNz_E08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "\n",
        "# GPT Base With Web Crawler Corpus Integrated and Higher-Order Approach.\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "6PSSHUG-6nb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import random\n",
        "import gpt_2_simple as gpt2\n",
        "\n",
        "# Function definitions for N-gram model\n",
        "def read_corpus(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        corpus = file.read()\n",
        "    return corpus\n",
        "\n",
        "def tokenize_corpus(corpus):\n",
        "    return nltk.word_tokenize(corpus)\n",
        "\n",
        "def build_flexible_ngram_model(tokenized_corpus, max_n=5):\n",
        "    ngrams = {}\n",
        "    for n in range(2, max_n + 1):\n",
        "        for i in range(len(tokenized_corpus) - n):\n",
        "            ngram = tuple(tokenized_corpus[i:i + n])\n",
        "            next_word = tokenized_corpus[i + n]\n",
        "            if ngram not in ngrams:\n",
        "                ngrams[ngram] = []\n",
        "            ngrams[ngram].append(next_word)\n",
        "    return ngrams\n",
        "\n",
        "def generate_ngram_continuation(prompt, ngrams, max_n, max_length=50):\n",
        "    prompt_words = nltk.word_tokenize(prompt)\n",
        "    continuation = prompt\n",
        "    for _ in range(max_length):\n",
        "        found = False\n",
        "        for n in range(max_n, 1, -1):\n",
        "            if len(prompt_words) >= n:\n",
        "                last_n_words = tuple(prompt_words[-n:])\n",
        "                if last_n_words in ngrams:\n",
        "                    next_word = random.choice(ngrams[last_n_words])\n",
        "                    prompt_words.append(next_word)\n",
        "                    continuation += \" \" + next_word\n",
        "                    found = True\n",
        "                    break\n",
        "        if not found:\n",
        "            break\n",
        "    return continuation\n",
        "\n",
        "# Function definitions for GPT-2 model\n",
        "def fine_tune_gpt2(corpus_path):\n",
        "    sess = gpt2.start_tf_sess()\n",
        "    try:\n",
        "        gpt2.finetune(sess,\n",
        "                      dataset=corpus_path,\n",
        "                      model_name='124M',\n",
        "                      steps=5)\n",
        "    finally:\n",
        "        gpt2.reset_session(sess)\n",
        "\n",
        "def generate_gpt2_continuation(prompt, length=50):\n",
        "    sess = gpt2.start_tf_sess()\n",
        "    try:\n",
        "        gpt2.load_gpt2(sess, model_name=\"124M\")\n",
        "        continuation = gpt2.generate(sess,\n",
        "                                     model_name=\"124M\",\n",
        "                                     prefix=prompt,\n",
        "                                     length=length,\n",
        "                                     return_as_list=True)[0]\n",
        "    finally:\n",
        "        gpt2.reset_session(sess)\n",
        "    return continuation\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    corpus_path = \"/content/website_text.txt\"\n",
        "    fine_tune_gpt2(corpus_path)\n",
        "    corpus = read_corpus(corpus_path)\n",
        "    tokenized_corpus = tokenize_corpus(corpus)\n",
        "    ngram_model = build_flexible_ngram_model(tokenized_corpus, max_n=7)\n",
        "\n",
        "    prompts = [\n",
        "        \"In the fall semester, the business department offers courses such as\",\n",
        "        \"To apply for financial aid and scholarships, students must \",\n",
        "        \"to apply for a graduate degree students must\",\n",
        "        \"Graduate students have research opportunities in areas like\",\n",
        "        \"On-campus housing options provide amenities such as\",\n",
        "        \"The university's policies on academic integrity include guidelines like\",\n",
        "        \"Students can engage in extracurricular activities such as\",\n",
        "        \"Support for international students includes services like\",\n",
        "        \"Submitting a thesis or dissertation requires steps such as\",\n",
        "        \"The university's career center offers services like\"\n",
        "    ]\n",
        "\n",
        "    for prompt in prompts:\n",
        "        print(\"Prompt:\", prompt)\n",
        "        continuation = generate_gpt2_continuation(prompt)\n",
        "        if len(continuation.split()) < 10:  # Example condition for fallback\n",
        "            continuation = generate_ngram_continuation(continuation, ngram_model, max_n=7)\n",
        "        print(\"Continuation:\", continuation)\n",
        "        print()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ag2MaSnS6r5B",
        "outputId": "8532703c-6324-47cf-8bd8-75f04a48cb45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint checkpoint/run1/model-10\n",
            "Loading dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [01:33<00:00, 93.73s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset has 17668215 tokens\n",
            "Training...\n",
            "[11 | 134.45] loss=5.30 avg=5.30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "# Read the corpus from the text file\n",
        "def read_corpus(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        corpus = file.read()\n",
        "    return corpus\n",
        "\n",
        "# Tokenize the corpus into words\n",
        "def tokenize_corpus(corpus):\n",
        "    return nltk.word_tokenize(corpus)\n",
        "\n",
        "# Build a flexible Ngram model supporting multiple orders\n",
        "def build_flexible_ngram_model(tokenized_corpus, max_n=5):\n",
        "    ngrams = {}\n",
        "    for n in range(2, max_n + 1):\n",
        "        temp_ngrams = defaultdict(list)\n",
        "        for i in range(len(tokenized_corpus) - n):\n",
        "            ngram = tuple(tokenized_corpus[i:i + n])\n",
        "            next_word = tokenized_corpus[i + n]\n",
        "            temp_ngrams[ngram].append(next_word)\n",
        "\n",
        "        # Convert list of words to probability distribution\n",
        "        for ngram, words in temp_ngrams.items():\n",
        "            word_counts = Counter(words)\n",
        "            total_count = sum(word_counts.values())\n",
        "            probabilities = {word: count / total_count for word, count in word_counts.items()}\n",
        "            ngrams[ngram] = probabilities\n",
        "\n",
        "    return ngrams\n"
      ],
      "metadata": {
        "id": "n0pLhk0a_1Ra"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Function to save the model to a pickle file\n",
        "def save_model_to_pickle(model, file_name='ngram_model.pkl'):\n",
        "    with open(file_name, 'wb') as f:\n",
        "        pickle.dump(model, f, protocol=pickle.HIGHEST_PROTOCOL)\n"
      ],
      "metadata": {
        "id": "TOiwebJn_2eE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}